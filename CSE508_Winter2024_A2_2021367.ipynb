{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NLhf1tWGG65z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1As5Xj5kLtEp",
        "outputId": "62f13639-221c-4df0-c433-d29a592ce095"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct path for the uploaded dataset file\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Display the first few rows of the dataframe to confirm it's loaded correctly\n",
        "#print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSTz4iNBNxaC",
        "outputId": "bd8db191-1c95-4763-80ef-3267a7cbd2a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Unnamed: 0                                              Image  \\\n",
            "0        3452  ['https://images-na.ssl-images-amazon.com/imag...   \n",
            "1        1205  ['https://images-na.ssl-images-amazon.com/imag...   \n",
            "2        1708  ['https://images-na.ssl-images-amazon.com/imag...   \n",
            "3        2078  ['https://images-na.ssl-images-amazon.com/imag...   \n",
            "4         801  ['https://images-na.ssl-images-amazon.com/imag...   \n",
            "\n",
            "                                         Review Text  \n",
            "0  Loving these vintage springs on my vintage str...  \n",
            "1  Works great as a guitar bench mat. Not rugged ...  \n",
            "2  We use these for everything from our acoustic ...  \n",
            "3  Great price and good quality.  It didn't quite...  \n",
            "4  I bought this bass to split time as my primary...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torchvision import models, transforms\n",
        "import requests\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "import nltk\n",
        "\n",
        "# Ensure NLTK resources are available\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "output_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "\n",
        "# Define image preprocessing pipeline\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Load the pre-trained ResNet model\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet.eval()  # Set model to evaluation mode\n",
        "\n",
        "def extract_image_features(url):\n",
        "    \"\"\"Extract image features from a given URL using ResNet50.\"\"\"\n",
        "    try:\n",
        "        if url.startswith(\"[\") and url.endswith(\"]\"):\n",
        "            # Convert string list representation to actual list\n",
        "            url = eval(url)[0]\n",
        "\n",
        "        response = requests.get(url)\n",
        "        img = Image.open(BytesIO(response.content)).convert('RGB')  # Convert to RGB\n",
        "        img_t = image_transforms(img)\n",
        "        img_t = img_t.unsqueeze(0)  # Add batch dimension\n",
        "        with torch.no_grad():  # No need for gradient computation\n",
        "            features = resnet(img_t)\n",
        "        return features.cpu().numpy().flatten()\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error fetching URL {url}: {e}\")\n",
        "    except UnidentifiedImageError:\n",
        "        print(f\"Cannot identify image file from URL {url}.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error for URL {url}: {e}\")\n",
        "    return None\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'  # Update this path\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "extracted_features = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    feature_vector = extract_image_features(row['Image'])  # Ensure 'Image' is the correct column name\n",
        "    if feature_vector is not None:\n",
        "        extracted_features.append(feature_vector)\n",
        "\n",
        "# Save the results\n",
        "features_file_path = os.path.join(output_dir, 'image_features_refactored.pkl')\n",
        "with open(features_file_path, 'wb') as f:\n",
        "    pickle.dump(extracted_features, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzY-EWDMXni5",
        "outputId": "c2fdfac7-2d17-4ae5-dd5b-727f69476b4d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/71F3npeHUDL._SY88.jpg.\n",
            "Cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/71B8OOE5N8L._SY88.jpg.\n",
            "Cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/718niQ1GEwL._SY88.jpg.\n",
            "Cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/61OboZT-kcL._SY88.jpg.\n",
            "Cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/710a2Pyh5lL._SY88.jpg.\n",
            "Cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/816NMd0LexL._SY88.jpg.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "# Download necessary NLTK datasets\n",
        "nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
        "\n",
        "def text_normalization_and_processing(input_text):\n",
        "    \"\"\"Normalize and process text data for analysis.\"\"\"\n",
        "    # Normalize text to lowercase\n",
        "    normalized_text = input_text.lower()\n",
        "    # Remove URLs and user mentions with regular expressions\n",
        "    cleaned_text = re.sub(r'\\b(http\\S+|@\\w+)\\b', '', normalized_text)\n",
        "    # Tokenize while removing punctuation\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(cleaned_text)\n",
        "    # Filter out stopwords and apply lemmatization\n",
        "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in english_stopwords]\n",
        "    return filtered_tokens\n",
        "\n",
        "# Set up environment for text processing\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "# Load dataset\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'  # Update this path\n",
        "df = pd.read_csv(dataset_path)\n",
        "# Preprocess reviews\n",
        "reviews = df['Review Text'].fillna(' ').apply(str).tolist()\n",
        "processed_reviews = [text_normalization_and_processing(review) for review in reviews]\n",
        "\n",
        "def tf_idf_computation(docs_tokens):\n",
        "    \"\"\"Compute the TF-IDF for each document.\"\"\"\n",
        "    # Term Frequency calculation\n",
        "    tf = [Counter(doc_tokens) for doc_tokens in docs_tokens]\n",
        "    # Document Frequency and Inverse Document Frequency\n",
        "    doc_count = float(len(docs_tokens))\n",
        "    idf = {}\n",
        "    for doc in tf:\n",
        "        for term in doc.keys():\n",
        "            idf[term] = idf.get(term, 0) + 1\n",
        "    for term, val in idf.items():\n",
        "        idf[term] = math.log(doc_count / val)\n",
        "\n",
        "    # TF-IDF calculation\n",
        "    tf_idf = []\n",
        "    for doc in tf:\n",
        "        doc_tf_idf = {}\n",
        "        for term, val in doc.items():\n",
        "            doc_tf_idf[term] = val * idf[term]\n",
        "        tf_idf.append(doc_tf_idf)\n",
        "\n",
        "    return tf_idf\n",
        "\n",
        "tf_idf_scores_refined = tf_idf_computation(processed_reviews)\n",
        "\n",
        "# Prepare directory for saving processed data\n",
        "data_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "# Saving processed data\n",
        "pickle.dump(processed_reviews, open(os.path.join(data_dir, 'refined_reviews.pkl'), 'wb'))\n",
        "pickle.dump(tf_idf_scores_refined, open(os.path.join(data_dir, 'refined_tf_idf.pkl'), 'wb'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPHap4O0guKU",
        "outputId": "000f7d98-2a6c-4d0a-bf37-6f276d1f0a68"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_t6lkE6zJciP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import torch\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Setting up file paths\n",
        "data_csv_path = '/content/drive/My Drive/IR_Assignment2/Data_A2.csv'\n",
        "output_path = '/content/drive/My Drive/IR_Assignment2'\n",
        "img_feat_path = os.path.join(output_path, 'img_feats.pkl')\n",
        "text_feat_path = os.path.join(output_path, 'text_features.pkl')\n",
        "\n",
        "# Loading the dataset and features\n",
        "data_frame = pd.read_csv(data_csv_path)\n",
        "with open(img_feat_path, 'rb') as img_file:\n",
        "    img_feats = pickle.load(img_file)\n",
        "with open(text_feat_path, 'rb') as text_file:\n",
        "    text_features = pickle.load(text_file)\n",
        "\n",
        "# Pretrained model for image feature extraction\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.eval()\n",
        "\n",
        "# Transformation pipeline for images\n",
        "img_transform = Compose([\n",
        "    Resize(256),\n",
        "    CenterCrop(224),\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "# Calculate cosine similarity\n",
        "def calc_cosine_sim(vector1, vectors):\n",
        "    norm_vector1 = vector1 / np.linalg.norm(vector1)\n",
        "    norm_vectors = vectors / np.linalg.norm(vectors, axis=1, keepdims=True)\n",
        "    return np.dot(norm_vectors, norm_vector1)\n",
        "\n",
        "# Identify most similar items\n",
        "def get_top_matches(processed, features, num_matches=3):\n",
        "    sim_scores = calc_cosine_sim(processed, np.array(features))\n",
        "    top_idxs = np.argsort(sim_scores)[-num_matches:][::-1]\n",
        "    return top_idxs, sim_scores[top_idxs]\n",
        "\n",
        "# Text processing and TF calculation\n",
        "def process_text(text):\n",
        "    cleaned_text = re.sub(r'\\W+', ' ', text.lower())\n",
        "    words = cleaned_text.split()\n",
        "    return Counter(words)\n",
        "\n",
        "def calc_tf(word_counts):\n",
        "    total_count = sum(word_counts.values())\n",
        "    return {word: count / total_count for word, count in word_counts.items()}\n",
        "\n",
        "# Image processing and feature extraction\n",
        "def process_img(url):\n",
        "    try:\n",
        "        img_response = requests.get(url)\n",
        "        img = Image.open(BytesIO(img_response.content)).convert('RGB')\n",
        "        img_processed = img_transform(img).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            img_features = model(img_processed)\n",
        "        return img_features.numpy().flatten()\n",
        "    except Exception as error:\n",
        "        print(f\"Failed to process image: {error}\")\n",
        "        return None\n",
        "\n",
        "# Input handling\n",
        "img_url = input(\"Image URL: \")\n",
        "review_text = input(\"Review Text: \")\n",
        "\n",
        "# Processing inputs\n",
        "token_counts = process_text(review_text)\n",
        "tf_review = calc_tf(token_counts)\n",
        "processed_img = process_img(img_url)\n",
        "\n",
        "if processed_img is not None:\n",
        "    # Finding similar images and reviews\n",
        "    img_indices, img_sims = get_top_matches(processed_img, list(img_feats.values()))\n",
        "    review_indices, review_sims = get_top_matches(tf_review, list(text_features.values()))\n",
        "\n",
        "    print(f\"Similar Image Indices: {img_indices}\\nImage Similarities: {img_sims}\")\n",
        "    print(f\"Similar Review Indices: {review_indices}\\nReview Similarities: {review_sims}\")\n",
        "else:\n",
        "    print(\"Failed to find the requested image or review in the dataset.\")\n",
        "\n",
        "# Storing results\n",
        "results = {\n",
        "    'image_indices': img_indices,\n",
        "    'image_similarities': img_sims,\n",
        "    'review_indices': review_indices,\n",
        "    'review_similarities': review_sims,\n",
        "}\n",
        "with open(os.path.join(output_path, 'results_refactored.pkl'), 'wb') as result_file:\n",
        "    pickle.dump(results, result_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSuQB7ISJb0S",
        "outputId": "5d168570-4e9b-4cd2-9ef7-98a663fed87e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the image URL:  https://images-na.ssl-images-amazon.com/images/I/81q5+IxFVUL._SY88.jpg\n",
            "Enter the review text: Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n",
            "Similar Image Indices: [  0  62 193]\n",
            "Image Similarities: [0.8524184, 0.836084, 0.8211998]\n",
            "Similar Review Indices: [  0 794 750]\n",
            "Review Similarities: [0.14284236057674865, 0.14002800840280094, 0.12369368723729023]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from scipy.spatial.distance import cdist\n",
        "import os\n",
        "import pandas as pd\n",
        "output_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "# Assuming output_dir is already defined\n",
        "results_path = os.path.join(output_dir, 'new_retrieval_results.pkl')\n",
        "\n",
        "with open(results_path, 'rb') as f:\n",
        "    retrieval_results = pickle.load(f)\n",
        "\n",
        "# Extract individual components from the loaded retrieval results\n",
        "similar_image_indices = retrieval_results['similar_image_indices']\n",
        "image_similarities = retrieval_results['image_similarities']\n",
        "similar_review_indices = retrieval_results['similar_review_indices']\n",
        "review_similarities = retrieval_results['review_similarities']\n",
        "\n",
        "\n",
        "def calculate_composite_scores(image_similarities, review_similarities):\n",
        "    composite_scores = []\n",
        "    for image_similarity, review_similarity in zip(image_similarities, review_similarities):\n",
        "        # Calculate the average similarity score for each pair\n",
        "        composite_score = (image_similarity + review_similarity) / 2\n",
        "        composite_scores.append(composite_score)\n",
        "    return composite_scores\n",
        "\n",
        "composite_scores = calculate_composite_scores(image_similarities, review_similarities)\n",
        "\n",
        "# Create a list of tuples (composite_score, image_index, review_index) and sort it\n",
        "ranked_pairs = sorted(zip(composite_scores, similar_image_indices, similar_review_indices), reverse=True, key=lambda x: x[0])\n",
        "\n",
        "# Display the ranked results\n",
        "print(\"Ranked Combined Retrieval Results:\")\n",
        "for rank, (comp_score, img_idx, rev_idx) in enumerate(ranked_pairs, start=1):\n",
        "    print(f\"Rank: {rank}, Image Index: {img_idx}, Review Index: {rev_idx}, Composite Score: {comp_score:.4f}\")\n",
        "\n",
        "\n",
        "ranked_results_path = os.path.join(output_dir, 'ranked_combined_retrieval_results.pkl')\n",
        "with open(ranked_results_path, 'wb') as f:\n",
        "    pickle.dump(ranked_pairs, f)\n",
        "\n",
        "print(f\"Ranked combined retrieval results saved to: {ranked_results_path} \\n\")\n",
        "\n",
        "\n",
        "def get_data_by_indices(df, image_indices, review_indices):\n",
        "    # Extract image URLs and reviews by indices\n",
        "    image_urls = df.loc[image_indices, 'Image'].tolist()\n",
        "    reviews = df.loc[review_indices, 'Review Text'].tolist()\n",
        "    return image_urls, reviews\n",
        "\n",
        "\n",
        "image_urls, reviews = get_data_by_indices(df, similar_image_indices, similar_review_indices)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N144fZRCoIMv",
        "outputId": "2c5d7775-ac59-45de-edb5-d60782fa2d01"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Combined Retrieval Results:\n",
            "Rank: 1, Image Index: 0, Review Index: 0, Composite Score: 0.4976\n",
            "Rank: 2, Image Index: 62, Review Index: 794, Composite Score: 0.4881\n",
            "Rank: 3, Image Index: 193, Review Index: 750, Composite Score: 0.4724\n",
            "Ranked combined retrieval results saved to: /content/drive/My Drive/IR_Assignment2/ranked_combined_retrieval_results.pkl \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "import pandas as pd\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "def calculate_composite_scores(image_similarities, review_similarities):\n",
        "    composite_scores = []\n",
        "    # Assuming image_similarities and review_similarities are aligned and of equal length\n",
        "    for i in range(len(image_similarities)):\n",
        "        comp_score = (image_similarities[i] + review_similarities[i]) / 2\n",
        "        composite_scores.append((i, i, comp_score))  # Use i for both indices, or adjust as needed\n",
        "    composite_scores.sort(key=lambda x: x[2], reverse=True)\n",
        "    return composite_scores\n",
        "\n",
        "\n",
        "\n",
        "## Calculate composite scores using only similarity scores\n",
        "composite_scores = calculate_composite_scores(image_similarities, review_similarities)\n",
        "\n",
        "## Display the combined retrieval results\n",
        "print(\"USING IMAGE RETRIEVAL\")\n",
        "for i, (img_idx, rev_idx, comp_score) in enumerate(composite_scores, start=1):\n",
        "\n",
        "     print(f\"{i}) Image URL: {image_urls[img_idx]}\")  # Example: Single URL or a list if applicable\n",
        "     print(f\"Review: {reviews[rev_idx]}\")\n",
        "     print(f\"Cosine similarity of images - {image_similarities[img_idx]:.4f}\")\n",
        "     print(f\"Cosine similarity of text - {review_similarities[rev_idx]:.4f}\\n\")\n",
        "\n",
        "\n",
        "composite_image_score = sum(image_similarities) / len(image_similarities)\n",
        "composite_text_score = sum(review_similarities) / len(review_similarities)\n",
        "final_composite_score = (composite_image_score + composite_text_score) / 2\n",
        "\n",
        "print(\"Composite similarity scores of images:\", f\"{composite_image_score:.4f}\")\n",
        "print(\"Composite similarity scores of text:\", f\"{composite_text_score:.4f}\")\n",
        "print(\"Final composite similarity score:\", f\"{final_composite_score:.4f}\\n\")\n",
        "\n",
        "\n",
        "print(\"USING TEXT RETRIEVAL\")\n",
        "for i, (img_idx, rev_idx, comp_score) in enumerate(composite_scores, start=1):\n",
        "\n",
        "     print(f\"{i}) Image URL: {image_urls[img_idx]}\")\n",
        "     print(f\"Review: {reviews[rev_idx]}\")\n",
        "     print(f\"Cosine similarity of images - {image_similarities[img_idx]:.4f}\")\n",
        "     print(f\"Cosine similarity of text - {review_similarities[rev_idx]:.4f}\\n\")\n",
        "\n",
        "final_composite_image_score = sum(image_similarities) / len(image_similarities)\n",
        "final_composite_text_score = sum(review_similarities) / len(review_similarities)\n",
        "final_composite_score = (final_composite_image_score + final_composite_text_score) / 2\n",
        "\n",
        "print(\"Composite similarity scores of images:\", final_composite_image_score)\n",
        "print(\"Composite similarity scores of text:\", final_composite_text_score)\n",
        "print(\"Final composite similarity score:\", final_composite_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z859BzYio2Gc",
        "outputId": "02936733-b0fc-4b01-b488-88653ccb33aa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING IMAGE RETRIEVAL\n",
            "1) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/81q5+IxFVUL._SY88.jpg']\n",
            "Review: Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n",
            "Cosine similarity of images - 0.8524\n",
            "Cosine similarity of text - 0.1428\n",
            "\n",
            "2) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71nSUnv7znL._SY88.jpg']\n",
            "Review: Good\n",
            "Cosine similarity of images - 0.8361\n",
            "Cosine similarity of text - 0.1400\n",
            "\n",
            "3) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/81Eq6y34BYL._SY88.jpg']\n",
            "Review: Great Quality, adjustable tension. Well made.\n",
            "Cosine similarity of images - 0.8212\n",
            "Cosine similarity of text - 0.1237\n",
            "\n",
            "Composite similarity scores of images: 0.8366\n",
            "Composite similarity scores of text: 0.1355\n",
            "Final composite similarity score: 0.4860\n",
            "\n",
            "USING TEXT RETRIEVAL\n",
            "1) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/81q5+IxFVUL._SY88.jpg']\n",
            "Review: Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n",
            "Cosine similarity of images - 0.8524\n",
            "Cosine similarity of text - 0.1428\n",
            "\n",
            "2) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71nSUnv7znL._SY88.jpg']\n",
            "Review: Good\n",
            "Cosine similarity of images - 0.8361\n",
            "Cosine similarity of text - 0.1400\n",
            "\n",
            "3) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/81Eq6y34BYL._SY88.jpg']\n",
            "Review: Great Quality, adjustable tension. Well made.\n",
            "Cosine similarity of images - 0.8212\n",
            "Cosine similarity of text - 0.1237\n",
            "\n",
            "Composite similarity scores of images: 0.8365674018859863\n",
            "Composite similarity scores of text: 0.13552135207227994\n",
            "Final composite similarity score: 0.48604437697913316\n"
          ]
        }
      ]
    }
  ]
}