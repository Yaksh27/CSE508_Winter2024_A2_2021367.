{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLhf1tWGG65z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1As5Xj5kLtEp",
        "outputId": "cd50c154-aa86-4d9c-a4ab-dbcb0bb031f1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "#print(df.head())\n"
      ],
      "metadata": {
        "id": "rSTz4iNBNxaC"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from torchvision import models, transforms\n",
        "import requests\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import requests\n",
        "from io import BytesIO\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import string\n",
        "from collections import defaultdict, Counter\n",
        "from math import log\n",
        "import ast\n",
        "\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "output_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "\n",
        "\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "resnet.eval()\n",
        "\n",
        "def extract_image_features(urls):\n",
        "    features_list = []\n",
        "    try:\n",
        "\n",
        "        urls = ast.literal_eval(urls) if isinstance(urls, str) and urls.startswith(\"[\") else [urls]\n",
        "        for url in urls:\n",
        "            try:\n",
        "                response = requests.get(url)\n",
        "                img = Image.open(BytesIO(response.content))\n",
        "                img_t = image_transforms(img)\n",
        "                img_t = img_t.unsqueeze(0)\n",
        "                with torch.no_grad():\n",
        "                    features = resnet(img_t)\n",
        "                features_list.append(features.cpu().numpy().flatten())\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"RequestException for URL {url}: {e}\")\n",
        "            except UnidentifiedImageError:\n",
        "                print(f\"UnidentifiedImageError: cannot identify image file from URL {url}.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error for URL {url}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing URL string {urls}: {e}\")\n",
        "    return features_list\n",
        "\n",
        "\n",
        "\n",
        "image_features = []\n",
        "for index, row in df.iterrows():\n",
        "\n",
        "    features_list = extract_image_features(row['Image'])\n",
        "    image_features.extend(features_list)\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "\n",
        "\n",
        "df = pd.read_csv(dataset_path)\n",
        "# Save the results\n",
        "with open(os.path.join(output_dir, 'image_features_2.pkl'), 'wb') as f:\n",
        "    pickle.dump(image_features, f)\n",
        "\n",
        "print(f\"Extracted and saved features for images.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzY-EWDMXni5",
        "outputId": "d2022fb8-e50a-4c16-85cd-297b6f3d4339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/71F3npeHUDL._SY88.jpg.\n",
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/71wHUWncMGL._SY88.jpg.\n",
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/71B8OOE5N8L._SY88.jpg.\n",
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/81SX3oAWbNL._SY88.jpg.\n",
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/718niQ1GEwL._SY88.jpg.\n",
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/61OboZT-kcL._SY88.jpg.\n",
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/710a2Pyh5lL._SY88.jpg.\n",
            "UnidentifiedImageError: cannot identify image file from URL https://images-na.ssl-images-amazon.com/images/I/816NMd0LexL._SY88.jpg.\n",
            "Extracted and saved features for images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "\n",
        "nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
        "\n",
        "def text_normalization_and_processing(input_text):\n",
        "    \"\"\"Normalize and process text data for analysis.\"\"\"\n",
        "\n",
        "    normalized_text = input_text.lower()\n",
        "\n",
        "    cleaned_text = re.sub(r'\\b(http\\S+|@\\w+)\\b', '', normalized_text)\n",
        "\n",
        "    tokenizer = RegexpTokenizer(r'\\w+')\n",
        "    tokens = tokenizer.tokenize(cleaned_text)\n",
        "\n",
        "    filtered_tokens = [stemmer.stem(word) for word in tokens if word not in english_stopwords]\n",
        "    return filtered_tokens\n",
        "\n",
        "\n",
        "english_stopwords = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "reviews = df['Review Text'].fillna(' ').apply(str).tolist()\n",
        "processed_reviews = [text_normalization_and_processing(review) for review in reviews]\n",
        "\n",
        "def tf_idf_computation(docs_tokens):\n",
        "    \"\"\"Compute the TF-IDF for each document.\"\"\"\n",
        "\n",
        "    tf = [Counter(doc_tokens) for doc_tokens in docs_tokens]\n",
        "\n",
        "    doc_count = float(len(docs_tokens))\n",
        "    idf = {}\n",
        "    for doc in tf:\n",
        "        for term in doc.keys():\n",
        "            idf[term] = idf.get(term, 0) + 1\n",
        "    for term, val in idf.items():\n",
        "        idf[term] = math.log(doc_count / val)\n",
        "\n",
        "\n",
        "    tf_idf = []\n",
        "    for doc in tf:\n",
        "        doc_tf_idf = {}\n",
        "        for term, val in doc.items():\n",
        "            doc_tf_idf[term] = val * idf[term]\n",
        "        tf_idf.append(doc_tf_idf)\n",
        "\n",
        "    return tf_idf\n",
        "\n",
        "tf_idf_scores_refined = tf_idf_computation(processed_reviews)\n",
        "\n",
        "\n",
        "data_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "os.makedirs(data_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "pickle.dump(processed_reviews, open(os.path.join(data_dir, 'processed_texts.pkl'), 'wb'))\n",
        "pickle.dump(tf_idf_scores_refined, open(os.path.join(data_dir, 'tf_idf_scores.pkl'), 'wb'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPHap4O0guKU",
        "outputId": "548818cf-dd49-415b-fb9b-2c11c1015d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "_t6lkE6zJciP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import requests\n",
        "from PIL import Image\n",
        "from torchvision import models, transforms\n",
        "from io import BytesIO\n",
        "import os\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "# Assuming nltk resources are already downloaded in your environment\n",
        "# nltk.download(['punkt', 'stopwords', 'wordnet'])\n",
        "\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "output_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "image_features_path = os.path.join(output_dir, 'image_features.pkl')\n",
        "tf_idf_scores_path = os.path.join(output_dir, 'tf_idf.pkl')\n",
        "\n",
        "# Load the dataset and the precomputed features\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "with open(image_features_path, 'rb') as f:\n",
        "    image_features = pickle.load(f)\n",
        "with open(tf_idf_scores_path, 'rb') as f:\n",
        "    tf_idf_scores = pickle.load(f)\n",
        "\n",
        "resnet_model = models.resnet50(pretrained=True)\n",
        "resnet_model.eval()\n",
        "\n",
        "transform_pipeline = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "def preprocess_image(image_url):\n",
        "    \"\"\"Fetch and preprocess an image from a URL, then extract features.\"\"\"\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
        "        processed_image = transform_pipeline(image).unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            features = resnet_model(processed_image)\n",
        "        features_np = features.numpy().flatten()\n",
        "        return features_np\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing image from URL {image_url}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Modified cosine similarity function is assumed to be defined here\n",
        "def cosine_similarity(v1, v2):\n",
        "\n",
        "  if isinstance(v1, np.ndarray) and all(isinstance(v, np.ndarray) for v in v2):\n",
        "\n",
        "          v2 = np.array(v2)\n",
        "\n",
        "          v1_norm = v1 / np.linalg.norm(v1)\n",
        "          v2_norm = v2 / np.linalg.norm(v2, axis=1)[:, np.newaxis]\n",
        "\n",
        "          similarities = np.dot(v1_norm, v2_norm.T)\n",
        "\n",
        "\n",
        "  elif isinstance(v1, dict) and all(isinstance(v, dict) for v in v2):\n",
        "          similarities = []\n",
        "          for tfidf_dict in v2:\n",
        "\n",
        "              common_terms = set(v1.keys()) & set(tfidf_dict.keys())\n",
        "              dot_product = sum(v1[term] * tfidf_dict[term] for term in common_terms)\n",
        "\n",
        "              norm_v1 = np.sqrt(sum(value ** 2 for value in v1.values()))\n",
        "              norm_v2 = np.sqrt(sum(value ** 2 for value in tfidf_dict.values()))\n",
        "              if norm_v1 == 0 or norm_v2 == 0:\n",
        "                  similarity = 0\n",
        "              else:\n",
        "                  similarity = dot_product / (norm_v1 * norm_v2)\n",
        "              similarities.append(similarity)\n",
        "          similarities = np.array(similarities)\n",
        "\n",
        "  else:\n",
        "          raise ValueError(\"Unsupported input types.\")\n",
        "\n",
        "  return similarities\n",
        "\n",
        "def access_elements_safely(indices, dataset, similarities, description=\"Item\"):\n",
        "    \"\"\"Safely access elements by indices, ensuring they are within bounds.\"\"\"\n",
        "    for i, idx in enumerate(indices):\n",
        "        if idx < len(dataset):\n",
        "            print(f\"{description} {i+1}: Index {idx} with similarity {similarities[i]:.4f}\")\n",
        "        else:\n",
        "            print(f\"{description} {i+1}: Index {idx} is out of bounds, skipping.\")\n",
        "\n",
        "\n",
        "input_image_url = input(\"Enter the image URL: \")\n",
        "input_review_text = input(\"Enter the review text: \")\n",
        "\n",
        "\n",
        "processed_image = preprocess_image(input_image_url)\n",
        "processed_tokens = preprocess_text(input_review_text)\n",
        "input_review_tfidf = compute_tf(processed_tokens)\n",
        "\n",
        "\n",
        "if processed_image is not None:\n",
        "    similar_image_indices, image_similarities = find_most_similar_images(processed_image, image_features)\n",
        "    similar_review_indices, review_similarities = find_most_similar_reviews(input_review_tfidf, tf_idf_scores)\n",
        "\n",
        "\n",
        "    print(\"Similar Images:\")\n",
        "    access_elements_safely(similar_image_indices, image_features, image_similarities, description=\"Image\")\n",
        "\n",
        "    print(\"\\nSimilar Reviews:\")\n",
        "    access_elements_safely(similar_review_indices, tf_idf_scores, review_similarities, description=\"Review\")\n",
        "else:\n",
        "    print(\"The specified image URL and review were not found in the dataset, or image processing failed.\")\n",
        "\n",
        "\n",
        "retrieval_results = {\n",
        "    'similar_image_indices': similar_image_indices,\n",
        "    'image_similarities': image_similarities,\n",
        "    'similar_review_indices': similar_review_indices,\n",
        "    'review_similarities': review_similarities,\n",
        "}\n",
        "results_path = os.path.join(output_dir, 'retrieval_results_new.pkl')\n",
        "with open(results_path, 'wb') as f:\n",
        "    pickle.dump(retrieval_results, f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSuQB7ISJb0S",
        "outputId": "26210c69-d994-48ef-cb25-7ff3a679c74f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the image URL: https://images-na.ssl-images-amazon.com/images/I/71bztfqdg+L._SY88.jpg\n",
            "Enter the review text: I have been using Fender locking tuners for about five years on various strats and teles. Definitely helps with tuning stability and way faster to restring if there is a break.\n",
            "Similar Images:\n",
            "Image 1: Index 1238 with similarity 0.9386\n",
            "Image 2: Index 1094 with similarity 0.8766\n",
            "Image 3: Index 1621 with similarity 0.8666\n",
            "\n",
            "Similar Reviews:\n",
            "Review 1: Index 758 with similarity 0.2609\n",
            "Review 2: Index 683 with similarity 0.0697\n",
            "Review 3: Index 622 with similarity 0.0649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "from scipy.spatial.distance import cdist\n",
        "import os\n",
        "import pandas as pd\n",
        "output_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "\n",
        "results_path = os.path.join(output_dir, 'retrieval_results_new.pkl')\n",
        "\n",
        "with open(results_path, 'rb') as f:\n",
        "    retrieval_results = pickle.load(f)\n",
        "\n",
        "similar_image_indices = retrieval_results['similar_image_indices']\n",
        "image_similarities = retrieval_results['image_similarities']\n",
        "similar_review_indices = retrieval_results['similar_review_indices']\n",
        "review_similarities = retrieval_results['review_similarities']\n",
        "\n",
        "\n",
        "def calculate_composite_scores(image_similarities, review_similarities):\n",
        "    composite_scores = []\n",
        "    for image_similarity, review_similarity in zip(image_similarities, review_similarities):\n",
        "\n",
        "        composite_score = (image_similarity + review_similarity) / 2\n",
        "        composite_scores.append(composite_score)\n",
        "    return composite_scores\n",
        "\n",
        "composite_scores = calculate_composite_scores(image_similarities, review_similarities)\n",
        "\n",
        "ranked_pairs = sorted(zip(composite_scores, similar_image_indices, similar_review_indices), reverse=True, key=lambda x: x[0])\n",
        "\n",
        "\n",
        "print(\"Ranked Combined Retrieval Results:\")\n",
        "for rank, (comp_score, img_idx, rev_idx) in enumerate(ranked_pairs, start=1):\n",
        "    print(f\"Rank: {rank}, Image Index: {img_idx}, Review Index: {rev_idx}, Composite Score: {comp_score:.4f}\")\n",
        "\n",
        "\n",
        "ranked_results_path = os.path.join(output_dir, 'ranked_combined_retrieval_results.pkl')\n",
        "with open(ranked_results_path, 'wb') as f:\n",
        "    pickle.dump(ranked_pairs, f)\n",
        "\n",
        "print(f\"Ranked combined retrieval results saved to: {ranked_results_path} \\n\")\n",
        "\n",
        "def get_data_by_indices(df, image_indices, review_indices):\n",
        "    max_index = df.index.max()\n",
        "    valid_image_indices = [idx for idx in image_indices if idx <= max_index]\n",
        "    valid_review_indices = [idx for idx in review_indices if idx <= max_index]\n",
        "\n",
        "    if not valid_image_indices or not valid_review_indices:\n",
        "        print(\"Error: Provided indices are out of DataFrame's range.\")\n",
        "        return [], []\n",
        "\n",
        "\n",
        "    image_urls = df.loc[valid_image_indices, 'Image'].tolist()\n",
        "    reviews = df.loc[valid_review_indices, 'Review Text'].tolist()\n",
        "    return image_urls, reviews\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N144fZRCoIMv",
        "outputId": "0e1ac656-dc1b-4bfb-e1cb-a35ed45c21a8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ranked Combined Retrieval Results:\n",
            "Rank: 1, Image Index: 1238, Review Index: 758, Composite Score: 0.5997\n",
            "Rank: 2, Image Index: 1094, Review Index: 683, Composite Score: 0.4732\n",
            "Rank: 3, Image Index: 1621, Review Index: 622, Composite Score: 0.4658\n",
            "Ranked combined retrieval results saved to: /content/drive/My Drive/IR_Assignment2/ranked_combined_retrieval_results.pkl \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "output_dir = '/content/drive/My Drive/IR_Assignment2'\n",
        "dataset_path = '/content/drive/My Drive/IR_Assignment2/A2_Data.csv'\n",
        "\n",
        "df = pd.read_csv(dataset_path)\n",
        "\n",
        "\n",
        "results_path = os.path.join(output_dir, 'retrieval_results_new.pkl')\n",
        "with open(results_path, 'rb') as f:\n",
        "    retrieval_results = pickle.load(f)\n",
        "\n",
        "\n",
        "similar_image_indices = retrieval_results['similar_image_indices']\n",
        "image_similarities = retrieval_results['image_similarities']\n",
        "similar_review_indices = retrieval_results['similar_review_indices']\n",
        "review_similarities = retrieval_results['review_similarities']\n",
        "\n",
        "\n",
        "def calculate_composite_scores(image_similarities, review_similarities):\n",
        "    composite_scores = [(i, (image_similarities[i] + review_similarities[i]) / 2) for i in range(len(image_similarities))]\n",
        "    composite_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "    return composite_scores\n",
        "\n",
        "composite_scores = calculate_composite_scores(image_similarities, review_similarities)\n",
        "\n",
        "\n",
        "def get_data_by_indices(df, indices):\n",
        "\n",
        "    valid_indices = [index for index in indices if index < len(df)]\n",
        "    if not valid_indices:\n",
        "        return [], []\n",
        "\n",
        "    image_urls = df.iloc[valid_indices]['Image'].tolist()\n",
        "    reviews = df.iloc[valid_indices]['Review Text'].tolist()\n",
        "    return image_urls, reviews\n",
        "\n",
        "\n",
        "def display_results(df, composite_scores, preprocessed_reviews=None):\n",
        "    print(\"USING IMAGE RETRIEVAL\")\n",
        "    for rank, (idx, comp_score) in enumerate(composite_scores, start=1):\n",
        "\n",
        "        if idx < len(df):\n",
        "            image_url = df.iloc[idx]['Image'] if 'Image' in df.columns else \"Image URL not available\"\n",
        "            review = df.iloc[idx]['Review Text'] if 'Review Text' in df.columns else \"Review not available\"\n",
        "            print(f\"{rank}) Image URL: {image_url}\")\n",
        "            print(f\"Review: {review}\")\n",
        "            print(f\"Cosine similarity of images - {image_similarities[idx]:.4f}\")\n",
        "            print(f\"Cosine similarity of text - {review_similarities[idx]:.4f}\\n\")\n",
        "        else:\n",
        "            print(f\"Skipping rank {rank} due to out-of-bound index.\")\n",
        "\n",
        "    if preprocessed_reviews:\n",
        "        print(\"USING TEXT RETRIEVAL\")\n",
        "        for rank, (idx, comp_score) in enumerate(composite_scores, start=1):\n",
        "            if idx < len(df) and idx < len(preprocessed_reviews):\n",
        "                image_url = df.iloc[idx]['Image'] if idx < len(df) and 'Image' in df.columns else \"Image URL not available\"\n",
        "                preprocessed_review = preprocessed_reviews[idx] if idx < len(preprocessed_reviews) else \"Preprocessed review not available\"\n",
        "                print(f\"{rank}) Image URL: {image_url}\")\n",
        "                print(f\"Preprocessed Review: {preprocessed_review}\")\n",
        "                print(f\"Cosine similarity of images - {image_similarities[idx]:.4f}\")\n",
        "                print(f\"Cosine similarity of text - {review_similarities[idx]:.4f}\\n\")\n",
        "            else:\n",
        "                print(f\"Skipping rank {rank} due to out-of-bound index.\")\n",
        "\n",
        "# Calculate composite scores\n",
        "composite_scores = calculate_composite_scores(image_similarities, review_similarities)\n",
        "\n",
        "# Display the results using the modified function\n",
        "display_results(df, composite_scores, preprocessed_reviews)\n",
        "\n",
        "# Save your processed reviews and retrieval results as before\n",
        "\n",
        "final_composite_image_score = sum(image_similarities) / len(image_similarities)\n",
        "final_composite_text_score = sum(review_similarities) / len(review_similarities)\n",
        "final_composite_score = (final_composite_image_score + final_composite_text_score) / 2\n",
        "\n",
        "print(\"Composite similarity scores of images:\", final_composite_image_score)\n",
        "print(\"Composite similarity scores of text:\", final_composite_text_score)\n",
        "print(\"Final composite similarity score:\", final_composite_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z859BzYio2Gc",
        "outputId": "718d92a3-1cc5-4fa2-fbaf-9486fa3f0d57"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USING IMAGE RETRIEVAL\n",
            "1) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/81q5+IxFVUL._SY88.jpg']\n",
            "Review: Loving these vintage springs on my vintage strat. They have a good tension and great stability. If you are floating your bridge and want the most out of your springs than these are the way to go.\n",
            "Cosine similarity of images - 0.9386\n",
            "Cosine similarity of text - 0.2609\n",
            "\n",
            "2) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71HSx4Y-5dL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71dVsYejzTL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71domStNfIL._SY88.jpg']\n",
            "Review: Works great as a guitar bench mat. Not rugged enough for abuse but if you take care of it, it will take care of you. Makes organization of workspace much easier because screws won't roll around. Color is good too.\n",
            "Cosine similarity of images - 0.8766\n",
            "Cosine similarity of text - 0.0697\n",
            "\n",
            "3) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71Md5ihUFLL._SY88.jpg']\n",
            "Review: We use these for everything from our acoustic bass down to our ukuleles. I know there is a smaller model available for ukes, violins, etc.; we haven't yet ordered those, but these will work on smaller instruments if one doesn't extend the feet to their maximum width. They're gentle on the instruments, and the grippy material keeps them secure.\n",
            "\n",
            "The greatest benefit has been when writing music at the computer and needing to set a guitar down to use the keyboard/mouse - just easier for me than a hanging stand.\n",
            "\n",
            "We have several and gave one to a friend for Christmas as well. I've used mine on stage, and it folds up small enough to fit right in my gig bag.\n",
            "Cosine similarity of images - 0.8666\n",
            "Cosine similarity of text - 0.0649\n",
            "\n",
            "USING TEXT RETRIEVAL\n",
            "1) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/81q5+IxFVUL._SY88.jpg']\n",
            "Preprocessed Review: ['love', 'vintag', 'spring', 'vintag', 'strat', 'good', 'tension', 'great', 'stabil', 'float', 'bridg', 'want', 'spring', 'way', 'go']\n",
            "Cosine similarity of images - 0.9386\n",
            "Cosine similarity of text - 0.2609\n",
            "\n",
            "2) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71HSx4Y-5dL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71dVsYejzTL._SY88.jpg', 'https://images-na.ssl-images-amazon.com/images/I/71domStNfIL._SY88.jpg']\n",
            "Preprocessed Review: ['work', 'great', 'guitar', 'bench', 'mat', 'rug', 'enough', 'abus', 'take', 'care', 'take', 'care', 'make', 'organ', 'workspac', 'much', 'easier', 'screw', 'roll', 'around', 'color', 'good']\n",
            "Cosine similarity of images - 0.8766\n",
            "Cosine similarity of text - 0.0697\n",
            "\n",
            "3) Image URL: ['https://images-na.ssl-images-amazon.com/images/I/71Md5ihUFLL._SY88.jpg']\n",
            "Preprocessed Review: ['use', 'everyth', 'acoust', 'bass', 'ukulel', 'know', 'smaller', 'model', 'avail', 'uke', 'violin', 'etc', 'yet', 'order', 'work', 'smaller', 'instrument', 'one', 'extend', 'feet', 'maximum', 'width', 'gentl', 'instrument', 'grippi', 'materi', 'keep', 'secur', 'greatest', 'benefit', 'write', 'music', 'comput', 'need', 'set', 'guitar', 'use', 'keyboard', 'mous', 'easier', 'hang', 'stand', 'sever', 'gave', 'one', 'friend', 'christma', 'well', 'use', 'mine', 'stage', 'fold', 'small', 'enough', 'fit', 'right', 'gig', 'bag']\n",
            "Cosine similarity of images - 0.8666\n",
            "Cosine similarity of text - 0.0649\n",
            "\n",
            "Composite similarity scores of images: 0.8939358393351237\n",
            "Composite similarity scores of text: 0.1318554296187668\n",
            "Final composite similarity score: 0.5128956344769452\n"
          ]
        }
      ]
    }
  ]
}